{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KROImpmqmoa3"
   },
   "source": [
    "# Laufzeit vorbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4330,
     "status": "ok",
     "timestamp": 1667770419549,
     "user": {
      "displayName": "Fabian Schwickert",
      "userId": "12141023081401838643"
     },
     "user_tz": -60
    },
    "id": "OcfKbLv0oKtL"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics import classification as metrics\n",
    "from torchvision.transforms import functional as augment_lib\n",
    "from torch.optim import lr_scheduler as scheduler\n",
    "\n",
    "import os\n",
    "from termcolor import colored\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "import shutil\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import GPUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46188,
     "status": "ok",
     "timestamp": 1667770473161,
     "user": {
      "displayName": "Fabian Schwickert",
      "userId": "12141023081401838643"
     },
     "user_tz": -60
    },
    "id": "iPhuDXcvmvT8",
    "outputId": "d8a11ce9-320d-4a91-8bcc-dff3e592d18c"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('Data/Underwater'):\n",
    "    ! pip install kaggle\n",
    "\n",
    "    ! mkdir Data / Underwater\n",
    "    ! kaggle datasets download ashish2001 / semantic-segmentation-of-underwater-imagery-suim\n",
    "    ! unzip semantic-segmentation-of-underwater-imagery-suim.zip -d Data / Underwater /\n",
    "    ! rm semantic-segmentation-of-underwater-imagery-suim.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('Modelle'):\n",
    "    ! mkdir Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1667770473162,
     "user": {
      "displayName": "Fabian Schwickert",
      "userId": "12141023081401838643"
     },
     "user_tz": -60
    },
    "id": "o6fmF0Lcmw3a",
    "outputId": "168602f7-d117-4d3c-eff7-bf5c1984a644"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "    print(\"using cuda: \", torch.cuda.get_device_name())\n",
    "\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    torch.set_default_tensor_type(torch.FloatTensor)\n",
    "    print(\"using cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PznDWh1GqyJV"
   },
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1667770477237,
     "user": {
      "displayName": "Fabian Schwickert",
      "userId": "12141023081401838643"
     },
     "user_tz": -60
    },
    "id": "joiUDgbGqyuP"
   },
   "outputs": [],
   "source": [
    "input_shape = [1024, 1024, 3]\n",
    "\n",
    "rgb2classes = {\n",
    "    (0, 0, 0): 0,  # Background (Schwarz)\n",
    "    (0, 0, 255): 1,  # Human diver (Blau)\n",
    "    (0, 255, 0): 2,  # Plant (Grün)\n",
    "    (0, 255, 255): 3,  # Wreck or ruin (Sky)\n",
    "    (255, 0, 0): 4,  # Robot (Rot)\n",
    "    (255, 0, 255): 5,  # Reef or invertebrate (Pink)\n",
    "    (255, 255, 0): 6,  # Fish or vertebrate (Gelb)\n",
    "    (255, 255, 255): 7  # Sea-floor or rock (Weiß)\n",
    "}\n",
    "\n",
    "classColorMap = ListedColormap([(r/255, g/255, b/255) for (r, g, b) in rgb2classes.keys()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def free_gpu_cache(tensors, print_out=False):\n",
    "    gpu = GPUtil.getGPUs()[0]\n",
    "\n",
    "    if print_out:\n",
    "        print(\"\\n\", \"=\" * 100, \"\\nBefore Clearing\")\n",
    "        GPUtil.showUtilization()\n",
    "\n",
    "    for tensor in tensors:\n",
    "        del tensor\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    if print_out:\n",
    "        print(\"\\nAfter Clearing\")\n",
    "        GPUtil.showUtilization()\n",
    "\n",
    "\n",
    "def plot_image(image, mask=None, image_color=True, image_cmap=None, mask_color=True, mask_cmap=None):\n",
    "    fig = plt.figure\n",
    "\n",
    "    if isinstance(image, torch.Tensor):\n",
    "        image = image.cpu().numpy()\n",
    "\n",
    "    if image_color:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    if image_cmap is not None:\n",
    "        plt.imshow(image, interpolation=\"nearest\", cmap=image_cmap)\n",
    "    else:\n",
    "        plt.imshow(image, interpolation=\"nearest\")\n",
    "\n",
    "    if mask is not None:\n",
    "        if isinstance(mask, torch.Tensor):\n",
    "            mask = mask.cpu().numpy()\n",
    "\n",
    "        if mask_color:\n",
    "            mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if mask_cmap is not None:\n",
    "            plt.imshow(mask, alpha=0.5, interpolation=\"nearest\", cmap=mask_cmap)\n",
    "        else:\n",
    "            plt.imshow(mask, alpha=0.5, interpolation=\"nearest\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_images(images: [], masks: [] = None, color=True, image_width=input_shape[0], image_height=input_shape[1], images_per_column=1, images_per_row=6):\n",
    "    fig, ax = plt.subplots(nrows=images_per_column, ncols=images_per_row, figsize=([128, 128]))\n",
    "\n",
    "    for index, axi in enumerate(ax.flat):\n",
    "        image = images[index]\n",
    "\n",
    "        if isinstance(image, torch.Tensor):\n",
    "            image = image.cpu().numpy()\n",
    "\n",
    "        if color:\n",
    "            image.reshape([image_width, image_height, 3])\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        #else:\n",
    "            #image = image.reshape([image_width, image_height, 1])\n",
    "\n",
    "        axi.imshow(image, interpolation=\"nearest\")\n",
    "\n",
    "        if masks is not None:\n",
    "            mask_tensor = masks[index]\n",
    "\n",
    "            mask_np = mask_tensor.reshape([image_width, image_width, 3])\n",
    "            mask_np = cv2.cvtColor(mask_np, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            axi.imshow(mask_np, interpolation=\"nearest\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def convert_rgb_to_class_feature_map(rgb_feature_map, num_classes=len(rgb2classes)):\n",
    "    class_feature_map = np.zeros([dim for dim in rgb_feature_map.shape[:2]] + [num_classes])\n",
    "\n",
    "    for row_index, rgb_row in enumerate(rgb_feature_map):\n",
    "        for field_index, rgb_field in enumerate(rgb_row):\n",
    "            rgb_field = tuple([\n",
    "                255 if channel > 126 else 0\n",
    "                for channel in rgb_field\n",
    "            ])\n",
    "\n",
    "\n",
    "            class_index = rgb2classes[rgb_field]\n",
    "            class_feature_map[row_index][field_index][class_index] = 1\n",
    "\n",
    "    return class_feature_map\n",
    "\n",
    "\n",
    "def convert_class_to_rgb_feature_map(class_feature_map):\n",
    "    class_feature_map = class_feature_map.reshape([class_feature_map.shape[0]] + [dim for dim in class_feature_map.shape[2:4]] + [class_feature_map.shape[1]]).squeeze()\n",
    "    rgb_feature_map = np.ndarray([dim for dim in class_feature_map.shape[0:2]] + [3])\n",
    "\n",
    "    for row_index, class_row in enumerate(class_feature_map):\n",
    "        for field_index, class_field in enumerate(class_row):\n",
    "            feature_class = np.where(class_field == 1)[0][0]\n",
    "\n",
    "            rgb_feature_map[row_index][field_index] = [rgb_color\n",
    "                                                       for rgb_color, mapped_feature_class\n",
    "                                                       in rgb2classes.items()\n",
    "                                                       if mapped_feature_class == feature_class][0]\n",
    "\n",
    "    return rgb_feature_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_more_rare(factor,current):\n",
    "    if factor > current:\n",
    "        return factor\n",
    "    else:\n",
    "        return current    \n",
    "\n",
    "\n",
    "def check_how_rare(rgb_label):\n",
    "    factor = 0\n",
    "    for x in range(150,900,7):\n",
    "        for y in range(150,900,7):\n",
    "            #print(rgb_label[x][y])\n",
    "            #print(\" x = \" + str(x) + \" y = \" + str(y) + \"=\" )\n",
    "            \n",
    "            if (rgb_label[x][y] & (255, 0, 0)).all(): # robot\n",
    "                print(\" The Factor is \" + 5)\n",
    "                return 5\n",
    "            elif (rgb_label[x][y] ==  (0, 255, 0)).all(): # plant\n",
    "                factor = 4      \n",
    "            elif (rgb_label[x][y] == (0, 255, 255)).all(): #ruin:\n",
    "                factor = is_more_rare(factor,3)       \n",
    "            elif (rgb_label[x][y] == (0, 0, 255)).all(): # Human\n",
    "                factor = is_more_rare(factor,2)            \n",
    "            elif (rgb_label[x][y] == (255, 255, 255)).all(): # rock   \n",
    "                 factor = is_more_rare(factor,1)       \n",
    "            else:\n",
    "                continue        \n",
    "    print(\"The Multiplier in the Preagumention is \" + str(factor))\n",
    "    return factor\n",
    "\n",
    "\n",
    "\n",
    "class Augmentation():\n",
    "    \n",
    "    def __init__(self,all_image):\n",
    "        self.all_image = all_image \n",
    "\n",
    "        factor = check_how_rare(all_image[1])\n",
    "        self.do_noise = False\n",
    "        self.do_sat = False\n",
    "        self.do_invert = False\n",
    "        self.saturation_options = []\n",
    "        self.invert_options = []\n",
    "\n",
    "        if (factor >= 1):\n",
    "            self.do_noise = True\n",
    "        if (factor >= 2):\n",
    "            self.do_sat = True\n",
    "            self.saturation_options.append(22)\n",
    "        if (factor >= 3):\n",
    "            self.saturation_options.append(44)\n",
    "        if (factor >= 4):\n",
    "            self.do_invert = True\n",
    "            self.invert_options.append(33)          \n",
    "        if (factor >= 5):\n",
    "            self.invert_options.append(66)\n",
    "\n",
    "# https://github.com/AISangam/Image-Augmentation-Using-OpenCV-and-Python/blob/master/Image%20Augmentaion%20Part1.py\n",
    "    def saturation_image(self,img):\n",
    "        result = []\n",
    "        for x in self.saturation_options:\n",
    "\n",
    "            image = cv2.cvtColor(img[0].copy(), cv2.COLOR_BGR2HSV)\n",
    "\n",
    "            v = image[:, :, 2]\n",
    "            v = np.where(v <= 255 - x, v + x, 255)\n",
    "            image[:, :, 2] = v\n",
    "\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_HSV2BGR)\n",
    "            result.append((image,img[1],img[2],img[3]))\n",
    "        return result\n",
    "\n",
    "\n",
    "    def invert(self,image,channel):\n",
    "        return (channel-image)\n",
    "\n",
    "\n",
    "    def invert_image(self,image):\n",
    "        result = []\n",
    "        for x in self.invert_options:\n",
    "            tmp = image[0].copy()\n",
    "            result.append((self.invert(tmp,x),image[1],image[2],image[3]))\n",
    "        return result\n",
    "\n",
    "    # https://github.com/AISangam/Image-Augmentation-Using-OpenCV-and-Python/blob/master/Image%20Augmentaion%20Part1.py\n",
    "    def addeptive_gaussian_noise(self,image):\n",
    "        \n",
    "        h,s,v=cv2.split(image[0])\n",
    "        s = cv2.adaptiveThreshold(s, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "        h = cv2.adaptiveThreshold(h, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "        v = cv2.adaptiveThreshold(v, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "        new=cv2.merge([h,s,v])\n",
    "        return [[new,image[1],image[2],image[3]]]\n",
    "\n",
    "\n",
    "    \n",
    "    def start(self):\n",
    "        \n",
    "        image = self.all_image\n",
    "        result  = [image]\n",
    "        if self.do_noise:\n",
    "            result += self.addeptive_gaussian_noise(image)\n",
    "        if self.do_invert:\n",
    "            result += self.invert_image(image)\n",
    "        if self.do_sat:\n",
    "            result += self.saturation_image(image)\n",
    "        print(\" Pre Aug did create \" + str(len(result)) + \"new Images\")\n",
    "        return result    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_u-ATVKm1II"
   },
   "source": [
    "# Datensatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1667770480659,
     "user": {
      "displayName": "Fabian Schwickert",
      "userId": "12141023081401838643"
     },
     "user_tz": -60
    },
    "id": "G67sNkEGm4i4"
   },
   "outputs": [],
   "source": [
    "class RttsDataset(Dataset):\n",
    "    def __init__(self, name, image_shape=input_shape, classes=rgb2classes):\n",
    "        self.name = name\n",
    "        self.classes = classes\n",
    "        self.image_shape = image_shape\n",
    "        self.entries = []\n",
    "\n",
    "    def load_entries(self, directory: str, starting_point=0, image_count=-1, augment=False, print_out=True):\n",
    "        start_image_count = len(self)\n",
    "        image_count_threshold = image_count * 10 if augment else image_count\n",
    "        list_of_image_files = os.listdir(directory + \"/images\")\n",
    "\n",
    "        print(\"\\n\", \"=\" * 10, \"Start loading entries\", \"=\" * 4, \"\\n\")\n",
    "        for index, filename in enumerate(list_of_image_files):\n",
    "            if starting_point <= index:\n",
    "                if image_count != -1 and (len(self) - start_image_count) == image_count_threshold:\n",
    "                    break\n",
    "\n",
    "                self.load_entry(directory, filename[:-4], augment=augment)\n",
    "\n",
    "                if print_out and index % 50 == 0 and index != 0:\n",
    "                    print(\"\\n\", \"=\" * 10, \"Loaded\", (index - starting_point), \"entries into\", self.name, \"=\" * 10, \"\\n\")\n",
    "\n",
    "        print(\"\\n\", \"=\" * 100, \"\\n\", self.name, \"contains\", len(self), \"entries.\\n\")\n",
    "\n",
    "    def load_entry(self, directory: str, file_name: str, augment=False):\n",
    "        image_file = os.path.join(directory + \"/images\", file_name + \".jpg\")\n",
    "        image = cv2.imread(image_file)\n",
    "        if image is None:\n",
    "            return\n",
    "\n",
    "        image: numpy.ndarray = cv2.resize(image, self.image_shape[:2])\n",
    "\n",
    "        rgb_label_file = os.path.join(directory + \"/masks\", file_name + \".bmp\")\n",
    "        rgb_label = cv2.imread(rgb_label_file)\n",
    "        if rgb_label is None:\n",
    "            return\n",
    "\n",
    "        rgb_label = cv2.resize(rgb_label, self.image_shape[:2])\n",
    "\n",
    "        class_label_path = directory + \"/class_labels/\"\n",
    "        class_label_filename = class_label_path + file_name + \".txt\"\n",
    "\n",
    "        if os.path.exists(class_label_filename):\n",
    "            class_label = np.loadtxt(class_label_filename, dtype=int)\n",
    "            class_label = class_label.reshape([dim for dim in rgb_label.shape[:2]] + [len(rgb2classes)])\n",
    "\n",
    "        else:\n",
    "            if not os.path.exists(class_label_path):\n",
    "                os.mkdir(class_label_path)\n",
    "\n",
    "            class_label = convert_rgb_to_class_feature_map(cv2.cvtColor(rgb_label, cv2.COLOR_BGR2RGB))\n",
    "            class_label = class_label.reshape([rgb_label.shape[0], rgb_label.shape[1] * len(rgb2classes)])\n",
    "            np.savetxt(class_label_filename, class_label, fmt=\"%d\")\n",
    "\n",
    "        edge = cv2.Canny(rgb_label, 0.1, 0.2)\n",
    "        kernel = np.ones((4, 4), np.uint8)\n",
    "        edge = (cv2.dilate(edge, kernel, iterations=1) > 50) * 1.0\n",
    "\n",
    "        image = np.array(image)\n",
    "        rgb_label = np.array(rgb_label)\n",
    "        class_label = np.array(class_label)\n",
    "        edge = np.array(edge)\n",
    "\n",
    "        if augment:\n",
    "      #     print(rgb_label)\n",
    "      #     print(class_label)\n",
    "           aug = Augmentation((image, rgb_label, class_label, edge))\n",
    "           #plot_image(rgb_label)\n",
    "           self.entries += aug.start()\n",
    "           #print(image_count)\n",
    "\n",
    "        else:\n",
    "            self.entries.append((image, rgb_label, class_label, edge))\n",
    "\n",
    "    def augment(self, entry):\n",
    "        image_np, rgb_label_np, class_label_np, edge_np = entry\n",
    "\n",
    "        image = torch.from_numpy(image_np)\n",
    "        rgb_label = torch.from_numpy(rgb_label_np)\n",
    "        class_label = torch.from_numpy(class_label_np)\n",
    "        edge = torch.from_numpy(edge_np).unsqueeze(dim=0)\n",
    "\n",
    "        self.entries += augment_entry(image, rgb_label, class_label, edge)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, rgb_label, class_label, edge = self.entries[index]\n",
    "\n",
    "        image_tensor = torch.Tensor(image) / 255\n",
    "        rgb_label_tensor = torch.from_numpy(rgb_label) / 255\n",
    "        class_label_tensor = torch.Tensor(class_label)\n",
    "        edge_tensor = torch.Tensor(edge)\n",
    "\n",
    "        return image_tensor, rgb_label_tensor, class_label_tensor, edge_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.entries)\n",
    "\n",
    "    def plot_image(self, index):\n",
    "        image_tensor, _, _, _ = self.__getitem__(index)\n",
    "        plot_image(image_tensor)\n",
    "\n",
    "    def plot_rgb_label(self, index):\n",
    "        _, label, _, _ = self.__getitem__(index)\n",
    "        plot_image(label)\n",
    "\n",
    "    def plot_class_label(self, index):\n",
    "        class_label = self.entries[index][2]\n",
    "        images = [\n",
    "            class_label[:, :, i]\n",
    "            for i in range(class_label.shape[2])\n",
    "        ]\n",
    "        plot_images(images=images, color=False, images_per_row=8)\n",
    "\n",
    "    def plot_edge(self, index):\n",
    "        _, _, _, edge_tensor = self.__getitem__(index)\n",
    "        plot_image(edge_tensor, image_color=False)\n",
    "\n",
    "    def plot_image_with_rgb_label(self, index):\n",
    "        image_tensor, label, _, _ = self.__getitem__(index)\n",
    "        plot_image(image_tensor, label)\n",
    "\n",
    "    def plot_images(self):\n",
    "        images = [image for image, _, _, _ in self.entries]\n",
    "        plot_images(images)\n",
    "\n",
    "    def plot_labels(self):\n",
    "        labels = [label for _, label, _, _ in self.entries]\n",
    "        plot_images(labels)\n",
    "\n",
    "    def plot_edges(self):\n",
    "        edges = [edge for _, _, _, edge in self.entries]\n",
    "        plot_images(edges, color=False)\n",
    "\n",
    "    def plot_images_with_rgb_label(self):\n",
    "        images = [image for image, _, _, _ in self.entries]\n",
    "        labels = [label for _, label, _, _ in self.entries]\n",
    "        plot_images(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14373,
     "status": "ok",
     "timestamp": 1667770495026,
     "user": {
      "displayName": "Fabian Schwickert",
      "userId": "12141023081401838643"
     },
     "user_tz": -60
    },
    "id": "Mob2b5xjm_G5",
    "outputId": "42c6d157-c14a-4490-f785-6d4ecc2ab59c"
   },
   "outputs": [],
   "source": [
    "train_dataset_path = \"Data/Underwater/train_val\"\n",
    "test_dataset_path = \"Data/Underwater/TEST\"\n",
    "\n",
    "train_set = RttsDataset(name=\"Train_Set\")\n",
    "train_set.load_entries(directory=train_dataset_path)\n",
    "\n",
    "test_set = RttsDataset(name=\"Test_Set\")\n",
    "test_set.load_entries(directory=test_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "executionInfo": {
     "elapsed": 5565,
     "status": "ok",
     "timestamp": 1667770500583,
     "user": {
      "displayName": "Fabian Schwickert",
      "userId": "12141023081401838643"
     },
     "user_tz": -60
    },
    "id": "ggASbE0nnBEK",
    "outputId": "75edad68-99b1-438b-c202-3be6e6bb3817"
   },
   "outputs": [],
   "source": [
    "image_index = 0\n",
    "train_set.plot_image(image_index)\n",
    "train_set.plot_rgb_label(image_index)\n",
    "train_set.plot_class_label(image_index)\n",
    "train_set.plot_edge(image_index)\n",
    "train_set.plot_image_with_rgb_label(image_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def augment_entry(image_tensor, rgb_label_tensor, class_label_tensor, edge_tensor):\n",
    "    result = []\n",
    "\n",
    "    if len(image_tensor.shape) == 3:\n",
    "        image_tensor = image_tensor.unsqueeze(dim=0)\n",
    "        rgb_label_tensor = rgb_label_tensor.unsqueeze(dim=0)\n",
    "        class_label_tensor = class_label_tensor.unsqueeze(dim=0)\n",
    "        edge_tensor = edge_tensor.unsqueeze(dim=0)\n",
    "\n",
    "    image_tensor = image_tensor.permute(0, 3, 1, 2)\n",
    "    rgb_label_tensor = rgb_label_tensor.permute(0, 3, 1, 2)\n",
    "    class_label_tensor = class_label_tensor.permute(0, 3, 1, 2)\n",
    "    edge_tensor = edge_tensor.unsqueeze(dim=3).permute(0, 3, 1, 2)\n",
    "\n",
    "    factor = random.random()\n",
    "\n",
    "    brightness_image = augment_lib.adjust_brightness(image_tensor, factor)\n",
    "    contrast_image = augment_lib.adjust_contrast(image_tensor, factor)\n",
    "    blured_image = augment_lib.gaussian_blur(image_tensor, kernel_size=random.choice([1,3,5,7,9]), sigma=factor)\n",
    "    color_invert_image = augment_lib.invert(image_tensor)\n",
    "\n",
    "    h_flipped_image = augment_lib.hflip(image_tensor)\n",
    "    h_flipped_rgb_label = augment_lib.hflip(rgb_label_tensor)\n",
    "    h_flipped_class_label = augment_lib.hflip(class_label_tensor)\n",
    "    h_flipped_edge = augment_lib.hflip(edge_tensor)\n",
    "\n",
    "    v_flipped_image = augment_lib.vflip(image_tensor)\n",
    "    v_flipped_rgb_label = augment_lib.vflip(rgb_label_tensor)\n",
    "    v_flipped_class_label = augment_lib.vflip(class_label_tensor)\n",
    "    v_flipped_edge = augment_lib.vflip(edge_tensor)\n",
    "\n",
    "    b_flipped_image = augment_lib.hflip(augment_lib.vflip(image_tensor))\n",
    "    b_flipped_rgb_label = augment_lib.hflip(augment_lib.vflip(rgb_label_tensor))\n",
    "    b_flipped_class_label = augment_lib.hflip(augment_lib.vflip(class_label_tensor))\n",
    "    b_flipped_edge = augment_lib.hflip(augment_lib.vflip(edge_tensor))\n",
    "\n",
    "    repetitions = 3 if 1 in class_label_tensor or 2 in class_label_tensor or 3 in class_label_tensor or 4 in class_label_tensor else 1\n",
    "\n",
    "    height = image_tensor.shape[2]\n",
    "    width = image_tensor.shape[3]\n",
    "\n",
    "    for _ in range(repetitions):\n",
    "        size = random.randint(300, 700)\n",
    "        top = random.randint(0, image_tensor.shape[3] - size)\n",
    "        left = random.randint(0, image_tensor.shape[2] - size)\n",
    "\n",
    "        cropped_image = F.interpolate(\n",
    "            input=augment_lib.crop(image_tensor, top=top, left=left, width=size, height=size),\n",
    "            size=[height, width],\n",
    "            mode='bilinear',\n",
    "            align_corners=False\n",
    "        )\n",
    "\n",
    "        cropped_rgb_label = F.interpolate(\n",
    "            input=augment_lib.crop(rgb_label_tensor, top=top, left=left, width=size, height=size),\n",
    "            size=[height, width],\n",
    "            mode='bilinear',\n",
    "            align_corners=False\n",
    "        )\n",
    "\n",
    "        cropped_class_label = F.interpolate(\n",
    "            input=augment_lib.crop(class_label_tensor, top=top, left=left, width=size, height=size),\n",
    "            size=[height, width],\n",
    "            mode='bilinear',\n",
    "            align_corners=False\n",
    "        )\n",
    "\n",
    "        cropped_edge = F.interpolate(\n",
    "            input=augment_lib.crop(edge_tensor, top=top, left=left, width=size, height=size),\n",
    "            size=[height, width],\n",
    "            mode='bilinear',\n",
    "            align_corners=False\n",
    "        )\n",
    "\n",
    "        result.append((cropped_image.permute(0, 2, 3, 1), cropped_rgb_label.permute(0, 2, 3, 1), cropped_class_label.permute(0, 2, 3, 1), cropped_edge.permute(0, 2, 3, 1)))\n",
    "\n",
    "    result.append((brightness_image.permute(0, 2, 3, 1), rgb_label_tensor.permute(0, 2, 3, 1), class_label_tensor.permute(0, 2, 3, 1), edge_tensor.permute(0, 2, 3, 1)))\n",
    "    result.append((contrast_image.permute(0, 2, 3, 1), rgb_label_tensor.permute(0, 2, 3, 1), class_label_tensor.permute(0, 2, 3, 1), edge_tensor.permute(0, 2, 3, 1)))\n",
    "    result.append((blured_image.permute(0, 2, 3, 1), rgb_label_tensor.permute(0, 2, 3, 1), class_label_tensor.permute(0, 2, 3, 1), edge_tensor.permute(0, 2, 3, 1)))\n",
    "    result.append((color_invert_image.permute(0, 2, 3, 1), rgb_label_tensor.permute(0, 2, 3, 1), class_label_tensor.permute(0, 2, 3, 1), edge_tensor.permute(0, 2, 3, 1)))\n",
    "    result.append((h_flipped_image.permute(0, 2, 3, 1), h_flipped_rgb_label.permute(0, 2, 3, 1), h_flipped_class_label.permute(0, 2, 3, 1), h_flipped_edge.permute(0, 2, 3, 1)))\n",
    "    result.append((v_flipped_image.permute(0, 2, 3, 1), v_flipped_rgb_label.permute(0, 2, 3, 1), v_flipped_class_label.permute(0, 2, 3, 1), v_flipped_edge.permute(0, 2, 3, 1)))\n",
    "    result.append((b_flipped_image.permute(0, 2, 3, 1), b_flipped_rgb_label.permute(0, 2, 3, 1), b_flipped_class_label.permute(0, 2, 3, 1), b_flipped_edge.permute(0, 2, 3, 1)))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batchnorm_momentum = 0.1\n",
    "align_corners = False\n",
    "loss_weights = torch.tensor([\n",
    "    1/1288,\n",
    "    1/405,\n",
    "    1/239,\n",
    "    1/275,\n",
    "    1/101,\n",
    "    1/1028,\n",
    "    1/1030,\n",
    "    1/635\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SemanticCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, ignore_label=-1, thres=0.7, min_kept=100_000, weight=None):\n",
    "        super(SemanticCrossEntropyLoss, self).__init__()\n",
    "\n",
    "        self.thresh = thres\n",
    "        self.min_kept = max(1, min_kept)\n",
    "        self.ignore_label = ignore_label\n",
    "        self.criterion = nn.CrossEntropyLoss(\n",
    "            weight=weight,\n",
    "            ignore_index=ignore_label,\n",
    "        )\n",
    "\n",
    "    def _ce_forward(self, prediction, target):\n",
    "        prediction = F.softmax(prediction, dim=1)\n",
    "        return self.criterion(prediction, target)\n",
    "\n",
    "    def _ohem_forward(self, prediction, target):\n",
    "        prediction = self._ce_forward(prediction, target).contiguous().view(-1)\n",
    "\n",
    "        return prediction.mean()\n",
    "\n",
    "    def forward(self, prediction, target):\n",
    "        if not (isinstance(prediction, list) or isinstance(prediction, tuple)):\n",
    "            prediction = [prediction]\n",
    "\n",
    "        balance_weights = [0.5, 0.5]\n",
    "        if len(balance_weights) == len(prediction):\n",
    "            functions = [self._ce_forward] * (len(balance_weights) - 1) + [self._ohem_forward]\n",
    "            return sum([\n",
    "                weight * func(x, target)\n",
    "                for (weight, x, func) in zip(balance_weights, prediction, functions)\n",
    "            ])\n",
    "\n",
    "        elif len(prediction) == 1:\n",
    "            return 0.5 * self._ohem_forward(prediction[0], target)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"lengths of prediction and target are not identical!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BoundaryLoss(nn.Module):\n",
    "    def __init__(self, coeff_bce=20.0):\n",
    "        super(BoundaryLoss, self).__init__()\n",
    "\n",
    "        self.coeff_bce = coeff_bce\n",
    "\n",
    "    def forward(self, prediction, target):\n",
    "        return self.coeff_bce * self.weighted_bce(prediction, target)\n",
    "\n",
    "    @staticmethod\n",
    "    def weighted_bce(prediction, target):\n",
    "        prediction = prediction.permute(0, 2, 3, 1).contiguous().view(1, -1)\n",
    "        target = target.view(1, -1)\n",
    "\n",
    "        pos_index = (target == 1)\n",
    "        neg_index = (target == 0)\n",
    "\n",
    "        weights = torch.zeros_like(prediction)\n",
    "        pos_num = pos_index.sum()\n",
    "        neg_num = neg_index.sum()\n",
    "        sum_num = pos_num + neg_num\n",
    "        weights[pos_index] = neg_num * 1.0 / sum_num\n",
    "        weights[neg_index] = pos_num * 1.0 / sum_num\n",
    "\n",
    "        loss = F.binary_cross_entropy_with_logits(prediction, target, weights, reduction='mean')\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_cSPary7xRC4"
   },
   "source": [
    "### Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None, no_relu=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.no_relu = no_relu\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(\n",
    "            num_features=out_channels,\n",
    "            momentum=batchnorm_momentum\n",
    "        )\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=out_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "        self.bn2 = nn.BatchNorm2d(\n",
    "            num_features=out_channels,\n",
    "            momentum=batchnorm_momentum\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "\n",
    "        if self.no_relu:\n",
    "            return out\n",
    "\n",
    "        return self.relu(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " class BottleneckBlock(nn.Module):\n",
    "    expansion = 2\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None, no_relu=True):\n",
    "        super(BottleneckBlock, self).__init__()\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.no_relu = no_relu\n",
    "\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=1,\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(\n",
    "            num_features=out_channels,\n",
    "            momentum=batchnorm_momentum\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=out_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "        self.bn2 = nn.BatchNorm2d(\n",
    "            num_features=out_channels,\n",
    "            momentum=batchnorm_momentum\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=out_channels,\n",
    "            out_channels=out_channels * self.expansion,\n",
    "            kernel_size=1,\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "        self.bn3 = nn.BatchNorm2d(\n",
    "            out_channels * self.expansion,\n",
    "            momentum=batchnorm_momentum\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "\n",
    "        if self.no_relu:\n",
    "            return out\n",
    "\n",
    "        return self.relu(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SegmentHead(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, inter_channels, out_channels, scale_factor=None):\n",
    "        super(SegmentHead, self).__init__()\n",
    "\n",
    "        self.scale_factor = scale_factor\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(\n",
    "            num_features=in_channels,\n",
    "            momentum=batchnorm_momentum\n",
    "        )\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=inter_channels,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "        self.bn2 = nn.BatchNorm2d(\n",
    "            num_features=inter_channels,\n",
    "            momentum=batchnorm_momentum\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=inter_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=1,\n",
    "            padding=0,\n",
    "            bias=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        out = self.bn2(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        if self.scale_factor is not None:\n",
    "            height = x.shape[-2] * self.scale_factor\n",
    "            width = x.shape[-1] * self.scale_factor\n",
    "\n",
    "            out = F.interpolate(\n",
    "                input=out,\n",
    "                size=[height, width],\n",
    "                mode='bilinear',\n",
    "                align_corners=align_corners\n",
    "            )\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PAPPM(nn.Module):\n",
    "    def __init__(self, in_channels, branch_channels, out_channels):\n",
    "        super(PAPPM, self).__init__()\n",
    "\n",
    "        self.scale0 = nn.Sequential(\n",
    "            nn.BatchNorm2d(\n",
    "                num_features=in_channels,\n",
    "                momentum=batchnorm_momentum\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=branch_channels,\n",
    "                kernel_size=1,\n",
    "                bias=False\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        self.scale1 = nn.Sequential(\n",
    "            nn.AvgPool2d(\n",
    "                kernel_size=5,\n",
    "                stride=2,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.BatchNorm2d(\n",
    "                num_features=in_channels,\n",
    "                momentum=batchnorm_momentum\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=branch_channels,\n",
    "                kernel_size=1,\n",
    "                bias=False\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        self.scale2 = nn.Sequential(\n",
    "            nn.AvgPool2d(\n",
    "                kernel_size=9,\n",
    "                stride=4,\n",
    "                padding=4\n",
    "            ),\n",
    "            nn.BatchNorm2d(\n",
    "                num_features=in_channels,\n",
    "                momentum=batchnorm_momentum\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=branch_channels,\n",
    "                kernel_size=1,\n",
    "                bias=False\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        self.scale3 = nn.Sequential(\n",
    "            nn.AvgPool2d(\n",
    "                kernel_size=17,\n",
    "                stride=8,\n",
    "                padding=8\n",
    "            ),\n",
    "            nn.BatchNorm2d(\n",
    "                num_features=in_channels,\n",
    "                momentum=batchnorm_momentum\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=branch_channels,\n",
    "                kernel_size=1,\n",
    "                bias=False\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        self.scale4 = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.BatchNorm2d(\n",
    "                num_features=in_channels,\n",
    "                momentum=batchnorm_momentum\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=branch_channels,\n",
    "                kernel_size=1,\n",
    "                bias=False\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        self.scale_process = nn.Sequential(\n",
    "            nn.BatchNorm2d(\n",
    "                num_features=branch_channels * 5,\n",
    "                momentum=batchnorm_momentum\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                in_channels=branch_channels * 5,\n",
    "                out_channels=branch_channels * 4,\n",
    "                kernel_size=3,\n",
    "                padding=1,\n",
    "                groups=4,\n",
    "                bias=False\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        self.compression = nn.Sequential(\n",
    "            nn.BatchNorm2d(\n",
    "                num_features=branch_channels * 5,\n",
    "                momentum=batchnorm_momentum\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                in_channels=branch_channels * 5,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=1,\n",
    "                bias=False\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.BatchNorm2d(\n",
    "                num_features=in_channels,\n",
    "                momentum=batchnorm_momentum\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=1,\n",
    "                bias=False\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        width = x.shape[-1]\n",
    "        height = x.shape[-2]\n",
    "\n",
    "        x_scale0 = self.scale0(x)\n",
    "\n",
    "        scale_list = [\n",
    "            x_scale0\n",
    "        ]\n",
    "\n",
    "        x_scale1 = F.interpolate(\n",
    "            input=self.scale1(x),\n",
    "            size=[height, width],\n",
    "            mode='bilinear',\n",
    "            align_corners=align_corners\n",
    "        ) + x_scale0\n",
    "        scale_list.append(x_scale1)\n",
    "\n",
    "        x_scale2 = F.interpolate(\n",
    "            input=self.scale2(x),\n",
    "            size=[height, width],\n",
    "            mode='bilinear',\n",
    "            align_corners=align_corners\n",
    "        ) + x_scale0\n",
    "        scale_list.append(x_scale2)\n",
    "\n",
    "        x_scale3 = F.interpolate(\n",
    "            input=self.scale3(x),\n",
    "            size=[height, width],\n",
    "            mode='bilinear',\n",
    "            align_corners=align_corners\n",
    "        ) + x_scale0\n",
    "        scale_list.append(x_scale3)\n",
    "\n",
    "        x_scale4 = F.interpolate(\n",
    "            input=self.scale4(x),\n",
    "            size=[height, width],\n",
    "            mode='bilinear',\n",
    "            align_corners=align_corners\n",
    "        ) + x_scale0\n",
    "        scale_list.append(x_scale4)\n",
    "\n",
    "        scale_out = self.scale_process(torch.cat(scale_list, 1))\n",
    "        out = self.compression(torch.cat([x_scale0, scale_out], 1)) + self.shortcut(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PagFM(nn.Module):\n",
    "    def __init__(self, in_channels, inter_channels, after_relu=False, with_channel=False):\n",
    "        super(PagFM, self).__init__()\n",
    "\n",
    "        self.with_channel = with_channel\n",
    "        self.after_relu = after_relu\n",
    "\n",
    "        self.f_x = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=inter_channels,\n",
    "                kernel_size=1,\n",
    "                bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(inter_channels)\n",
    "        )\n",
    "\n",
    "        self.f_y = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=inter_channels,\n",
    "                kernel_size=1,\n",
    "                bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(inter_channels)\n",
    "        )\n",
    "\n",
    "        if with_channel:\n",
    "            self.up = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=inter_channels,\n",
    "                    out_channels=in_channels,\n",
    "                    kernel_size=1,\n",
    "                    bias=False\n",
    "                ),\n",
    "                nn.BatchNorm2d(in_channels)\n",
    "            )\n",
    "\n",
    "        if after_relu:\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        input_size = x.size()\n",
    "\n",
    "        if self.after_relu:\n",
    "            y = self.relu(y)\n",
    "            x = self.relu(x)\n",
    "\n",
    "        y_q = self.f_y(y)\n",
    "        y_q = F.interpolate(\n",
    "            input=y_q,\n",
    "            size=[input_size[2], input_size[3]],\n",
    "            mode='bilinear',\n",
    "            align_corners=False\n",
    "        )\n",
    "\n",
    "        x_k = self.f_x(x)\n",
    "\n",
    "        if self.with_channel:\n",
    "            sim_map = torch.sigmoid(self.up(x_k * y_q))\n",
    "        else:\n",
    "            sim_map = torch.sigmoid(torch.sum(x_k * y_q, dim=1).unsqueeze(1))\n",
    "\n",
    "        y = F.interpolate(\n",
    "            input=y,\n",
    "            size=[input_size[2], input_size[3]],\n",
    "            mode='bilinear',\n",
    "            align_corners=False\n",
    "        )\n",
    "        x = (1 - sim_map) * x + sim_map * y\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LightBag(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(LightBag, self).__init__()\n",
    "\n",
    "        self.conv_p = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=1,\n",
    "                bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "        self.conv_i = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=1,\n",
    "                bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, p, i, d):\n",
    "        edge_att = torch.sigmoid(d)\n",
    "\n",
    "        p_add = self.conv_p((1 - edge_att) * i + p)\n",
    "        i_add = self.conv_i(i + edge_att * p)\n",
    "\n",
    "        return p_add + i_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LightBagV2(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(LightBagV2, self).__init__()\n",
    "\n",
    "        self.conv_p = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=1,\n",
    "                bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "        self.conv_i = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=1,\n",
    "                bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, p, i, d):\n",
    "        edge_att = torch.sigmoid(d)\n",
    "\n",
    "        p_add = self.conv_p((1 - edge_att) * i + p)\n",
    "        i_add = self.conv_i(i + edge_att * p)\n",
    "\n",
    "        return p_add + i_add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PIDNet(nn.Module):\n",
    "    def __init__(self, name: str, learning_rate: float, in_channels=3, out_channels=32, ppm_channels=96, head_channels=128, num_classes=len(rgb2classes), loss_weights=None):\n",
    "        super(PIDNet, self).__init__()\n",
    "\n",
    "        self.name = name\n",
    "        self.epochsTrained = 0\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # I Branch\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(\n",
    "                num_features=out_channels,\n",
    "                momentum=batchnorm_momentum\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                in_channels=out_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(\n",
    "                num_features=out_channels,\n",
    "                momentum=batchnorm_momentum\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.layer1 = self.__make_layer(\n",
    "            block=BasicBlock,\n",
    "            in_channels=out_channels,\n",
    "            out_channels=out_channels,\n",
    "            blocks=2\n",
    "        )\n",
    "\n",
    "        self.layer2 = self.__make_layer(\n",
    "            block=BasicBlock,\n",
    "            in_channels=out_channels,\n",
    "            out_channels=out_channels * 2,\n",
    "            blocks=2,\n",
    "            stride=2\n",
    "        )\n",
    "\n",
    "        self.layer3 = self.__make_layer(\n",
    "            block=BasicBlock,\n",
    "            in_channels=out_channels * 2,\n",
    "            out_channels=out_channels * 4,\n",
    "            blocks=3,\n",
    "            stride=2\n",
    "        )\n",
    "\n",
    "        self.layer4 = self.__make_layer(\n",
    "            block=BasicBlock,\n",
    "            in_channels=out_channels * 4,\n",
    "            out_channels=out_channels * 8,\n",
    "            blocks=3,\n",
    "            stride=2\n",
    "        )\n",
    "\n",
    "        self.layer5 = self.__make_layer(\n",
    "            block=BottleneckBlock,\n",
    "            in_channels=out_channels * 8,\n",
    "            out_channels=out_channels * 8,\n",
    "            blocks=2,\n",
    "            stride=2\n",
    "        )\n",
    "\n",
    "        # P Branch\n",
    "        self.compression3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=out_channels * 4,\n",
    "                out_channels=out_channels * 2,\n",
    "                kernel_size=1,\n",
    "                bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(\n",
    "                num_features=out_channels * 2,\n",
    "                momentum=batchnorm_momentum\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        self.compression4 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=out_channels * 8,\n",
    "                out_channels=out_channels * 2,\n",
    "                kernel_size=1,\n",
    "                bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(\n",
    "                num_features=out_channels * 2,\n",
    "                momentum=batchnorm_momentum\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        self.pag3 = PagFM(\n",
    "            in_channels=out_channels * 2,\n",
    "            inter_channels=out_channels\n",
    "        )\n",
    "\n",
    "        self.pag4 = PagFM(\n",
    "            in_channels=out_channels * 2,\n",
    "            inter_channels=out_channels\n",
    "        )\n",
    "\n",
    "        self.layer3_ = self.__make_layer(\n",
    "            block=BasicBlock,\n",
    "            in_channels=out_channels * 2,\n",
    "            out_channels=out_channels * 2,\n",
    "            blocks=2\n",
    "\n",
    "        )\n",
    "        self.layer4_ = self.__make_layer(\n",
    "            block=BasicBlock,\n",
    "            in_channels=out_channels * 2,\n",
    "            out_channels=out_channels * 2,\n",
    "            blocks=2\n",
    "        )\n",
    "\n",
    "        self.layer5_ = self.__make_layer(\n",
    "            block=BottleneckBlock,\n",
    "            in_channels=out_channels * 2,\n",
    "            out_channels=out_channels * 2,\n",
    "            blocks=1\n",
    "        )\n",
    "\n",
    "        # D Branch\n",
    "        self.layer3_d = self.__make_single_layer(\n",
    "            block=BasicBlock,\n",
    "            in_channels=out_channels * 2,\n",
    "            out_channels=out_channels\n",
    "        )\n",
    "\n",
    "        self.layer4_d = self.__make_layer(\n",
    "            block=BottleneckBlock,\n",
    "            in_channels=out_channels,\n",
    "            out_channels=out_channels,\n",
    "            blocks=1\n",
    "        )\n",
    "\n",
    "        self.diff3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=out_channels * 4,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=3,\n",
    "                padding=1,\n",
    "                bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(\n",
    "                num_features=out_channels,\n",
    "                momentum=batchnorm_momentum\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        self.diff4 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=out_channels * 8,\n",
    "                out_channels=out_channels * 2,\n",
    "                kernel_size=3,\n",
    "                padding=1,\n",
    "                bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(\n",
    "                num_features=out_channels * 2,\n",
    "                momentum=batchnorm_momentum\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        self.spp = PAPPM(\n",
    "            in_channels=out_channels * 16,\n",
    "            branch_channels=ppm_channels,\n",
    "            out_channels=out_channels * 4\n",
    "        )\n",
    "\n",
    "        self.dfm = LightBagV2(\n",
    "            in_channels=out_channels * 4,\n",
    "            out_channels=out_channels * 4\n",
    "        )\n",
    "\n",
    "        self.layer5_d = self.__make_layer(\n",
    "            block=BottleneckBlock,\n",
    "            in_channels=out_channels * 2,\n",
    "            out_channels=out_channels * 2,\n",
    "            blocks=1\n",
    "        )\n",
    "\n",
    "        # Prediction Head\n",
    "        self.seghead_p = SegmentHead(\n",
    "            in_channels=out_channels * 2,\n",
    "            inter_channels=head_channels,\n",
    "            out_channels=num_classes\n",
    "        )\n",
    "\n",
    "        self.seghead_d = SegmentHead(\n",
    "            in_channels=out_channels * 2,\n",
    "            inter_channels=out_channels,\n",
    "            out_channels=1\n",
    "        )\n",
    "\n",
    "\n",
    "        self.final_layer = SegmentHead(\n",
    "            in_channels=out_channels * 4,\n",
    "            inter_channels=head_channels,\n",
    "            out_channels=num_classes\n",
    "        )\n",
    "\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    tensor=m.weight,\n",
    "                    mode='fan_out',\n",
    "                    nonlinearity='relu'\n",
    "                )\n",
    "\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        self.semantic_loss_function = SemanticCrossEntropyLoss(\n",
    "            ignore_label=-1,\n",
    "            thres=0.9,\n",
    "            min_kept=100_000,\n",
    "            weight=loss_weights\n",
    "        )\n",
    "\n",
    "        self.boundary_loss_function = BoundaryLoss()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.optimiser = optim.SGD(\n",
    "            self.parameters(),\n",
    "            lr=learning_rate,\n",
    "            momentum=0.9,\n",
    "            weight_decay=0.0001,\n",
    "            nesterov=False\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def __make_layer(block, in_channels, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "\n",
    "        if stride != 1 or in_channels != out_channels * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=in_channels,\n",
    "                    out_channels=out_channels * block.expansion,\n",
    "                    kernel_size=1,\n",
    "                    stride=stride,\n",
    "                    bias=False\n",
    "                ),\n",
    "                nn.BatchNorm2d(\n",
    "                    num_features=out_channels * block.expansion,\n",
    "                    momentum=batchnorm_momentum\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(in_channels, out_channels, stride, downsample)\n",
    "        )\n",
    "\n",
    "        in_channels = out_channels * block.expansion\n",
    "\n",
    "        for i in range(1, blocks):\n",
    "            if i == (blocks - 1):\n",
    "                layers.append(\n",
    "                    block(in_channels, out_channels, stride=1, no_relu=True)\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                layers.append(\n",
    "                    block(in_channels, out_channels, stride=1, no_relu=False)\n",
    "                )\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    @staticmethod\n",
    "    def __make_single_layer(block, in_channels, out_channels, stride=1):\n",
    "        downsample = None\n",
    "\n",
    "        if stride != 1 or in_channels != out_channels * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=in_channels,\n",
    "                    out_channels=out_channels * block.expansion,\n",
    "                    kernel_size=1,\n",
    "                    stride=stride,\n",
    "                    bias=False\n",
    "                ),\n",
    "                nn.BatchNorm2d(\n",
    "                    num_features=out_channels * block.expansion,\n",
    "                    momentum=batchnorm_momentum\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        layer = block(in_channels, out_channels, stride, downsample, no_relu=True)\n",
    "\n",
    "        return layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        width_output = x.shape[-1] // 8\n",
    "        height_output = x.shape[-2] // 8\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x_ = self.layer3_(x)\n",
    "        x_d = self.layer3_d(x)\n",
    "\n",
    "        x = self.layer3(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x_ = self.pag3(x_, self.compression3(x))\n",
    "        x_d = x_d + F.interpolate(\n",
    "            input=self.diff3(x),\n",
    "            size=[height_output, width_output],\n",
    "            mode='bilinear',\n",
    "            align_corners=align_corners\n",
    "        )\n",
    "\n",
    "        temp_p = x_\n",
    "\n",
    "        x = self.layer4(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x_ = self.relu(x_)\n",
    "        x_ = self.layer4_(x_)\n",
    "\n",
    "        x_d = self.relu(x_d)\n",
    "        x_d = self.layer4_d(x_d)\n",
    "\n",
    "        x_ = self.pag4(x_, self.compression4(x))\n",
    "        x_d = x_d + F.interpolate(\n",
    "            input=self.diff4(x),\n",
    "            size=[height_output, width_output],\n",
    "            mode='bilinear',\n",
    "            align_corners=align_corners\n",
    "        )\n",
    "\n",
    "        temp_d = x_d\n",
    "\n",
    "        x_ = self.relu(x_)\n",
    "        x_ = self.layer5_(x_)\n",
    "\n",
    "        x_d = self.relu(x_d)\n",
    "        x_d = self.layer5_d(x_d)\n",
    "\n",
    "        x = F.interpolate(\n",
    "            self.spp(self.layer5(x)),\n",
    "            size=[height_output, width_output],\n",
    "            mode='bilinear',\n",
    "            align_corners=align_corners\n",
    "        )\n",
    "\n",
    "        x_ = self.final_layer(self.dfm(x_, x, x_d))\n",
    "\n",
    "        x_extra_p = self.seghead_p(temp_p)\n",
    "        x_extra_d = self.seghead_d(temp_d)\n",
    "\n",
    "        return x_extra_p, x_, x_extra_d\n",
    "\n",
    "    train_mode = 0\n",
    "    test_mode = 1\n",
    "\n",
    "    def __predict(self, image_tensor, output_height, output_width):\n",
    "        image_tensor = image_tensor.permute(0, 3, 1, 2)\n",
    "\n",
    "        prediction_start_ts = datetime.now()\n",
    "\n",
    "        batch_p_branch_prediction_tensor, batch_i_branch_prediction_tensor, batch_d_branch_prediction_tensor = self.forward(image_tensor)\n",
    "\n",
    "        prediction_stop_ts = datetime.now()\n",
    "        prediction_time = (prediction_stop_ts - prediction_start_ts).total_seconds() * 1_000_000\n",
    "\n",
    "        p_prediction_height, p_prediction_width = batch_i_branch_prediction_tensor.size(2), batch_i_branch_prediction_tensor.size(3)\n",
    "        i_prediction_height, i_prediction_width = batch_i_branch_prediction_tensor.size(2), batch_i_branch_prediction_tensor.size(3)\n",
    "        d_prediction_height, d_prediction_width = batch_i_branch_prediction_tensor.size(2), batch_i_branch_prediction_tensor.size(3)\n",
    "\n",
    "        if p_prediction_height != output_height or p_prediction_height != output_width:\n",
    "            batch_p_branch_prediction_tensor = F.interpolate(\n",
    "                batch_p_branch_prediction_tensor,\n",
    "                size=(output_height, output_width),\n",
    "                mode='bilinear',\n",
    "                align_corners=True\n",
    "            )\n",
    "\n",
    "        if i_prediction_height != output_height or i_prediction_height != output_width:\n",
    "            batch_i_branch_prediction_tensor = F.interpolate(\n",
    "                batch_i_branch_prediction_tensor,\n",
    "                size=(output_height, output_width),\n",
    "                mode='bilinear',\n",
    "                align_corners=True\n",
    "            )\n",
    "\n",
    "        if d_prediction_height != output_height or d_prediction_height != output_width:\n",
    "            batch_d_branch_prediction_tensor = F.interpolate(\n",
    "                batch_d_branch_prediction_tensor,\n",
    "                size=(output_height, output_width),\n",
    "                mode='bilinear',\n",
    "                align_corners=True\n",
    "            )\n",
    "\n",
    "        return batch_p_branch_prediction_tensor, batch_i_branch_prediction_tensor, batch_d_branch_prediction_tensor, prediction_time\n",
    "\n",
    "    def predict(self, image_tensor, output_height, output_width, plot=False):\n",
    "        if len(image_tensor.shape) == 3:\n",
    "            image_tensor = image_tensor.unsqueeze(dim=0)\n",
    "\n",
    "        _, prediction, _ = self.forward(\n",
    "            image_tensor.permute(0, 3, 1, 2)\n",
    "        )\n",
    "\n",
    "        prediction = F.softmax(\n",
    "            prediction.detach(),\n",
    "            dim=1\n",
    "        )\n",
    "\n",
    "        prediction_height, prediction_width = prediction.size(1), prediction.size(2)\n",
    "        if prediction_height != output_height or prediction_height != output_width:\n",
    "            prediction = F.interpolate(\n",
    "                prediction,\n",
    "                size=(output_height, output_width),\n",
    "                mode='bilinear',\n",
    "                align_corners=True\n",
    "            )\n",
    "\n",
    "        prediction = torch.argmax(\n",
    "            prediction.squeeze().permute(1, 2, 0),\n",
    "            dim=2\n",
    "        )\n",
    "\n",
    "        if plot:\n",
    "            plot_image(image_tensor.squeeze(), image_color=True)\n",
    "            plot_image(prediction, image_color=False, image_cmap=classColorMap)\n",
    "            plot_image(image_tensor.squeeze(), mask=prediction, mask_color=False, mask_cmap=classColorMap)\n",
    "\n",
    "        return prediction\n",
    "\n",
    "    def process_data(self, mode: int, batch_image_tensor, batch_image_label_tensor, batch_boundary_label_tensor, print_out=False):\n",
    "        batch_image_label_tensor = batch_image_label_tensor.permute(0, 3, 1, 2)\n",
    "        label_height, label_width = batch_image_label_tensor.size(2), batch_image_label_tensor.size(3)\n",
    "\n",
    "        batch_p_branch_prediction_tensor, batch_i_branch_prediction_tensor, batch_d_branch_prediction_tensor, prediction_time = self.__predict(batch_image_tensor, label_height, label_width)\n",
    "\n",
    "        iou, pixel_accuracy = self.calc_metrics(batch_i_branch_prediction_tensor, batch_image_label_tensor)\n",
    "\n",
    "        semantic_loss = self.semantic_loss_function([batch_p_branch_prediction_tensor, batch_i_branch_prediction_tensor], batch_image_label_tensor)\n",
    "        boundary_loss = self.boundary_loss_function(batch_d_branch_prediction_tensor, batch_boundary_label_tensor)\n",
    "\n",
    "        filler = torch.ones_like(batch_image_label_tensor) * -1\n",
    "        boundary_label = torch.where(\n",
    "            torch.sigmoid(batch_d_branch_prediction_tensor) > 0.8,\n",
    "            batch_image_label_tensor,\n",
    "            filler\n",
    "        )\n",
    "        combined_loss = self.semantic_loss_function(batch_i_branch_prediction_tensor, boundary_label)\n",
    "\n",
    "        full_loss = semantic_loss + boundary_loss + combined_loss\n",
    "        full_loss = torch.unsqueeze(full_loss, 0).mean()\n",
    "\n",
    "        if print_out:\n",
    "            print(\n",
    "                \"\\n=\" * 100,\n",
    "                \"\\nPixel_Accuracy:\", pixel_accuracy,\n",
    "                \"\\nSemantic Loss:\", semantic_loss,\n",
    "                \"\\nBoundary Loss:\", boundary_loss,\n",
    "                \"\\nCombined Loss:\", combined_loss,\n",
    "                \"\\nFull Loss:\", full_loss\n",
    "            )\n",
    "\n",
    "        if mode == PIDNet.train_mode:\n",
    "            self.optimiser.zero_grad(set_to_none=True)\n",
    "            full_loss.backward()\n",
    "            self.optimiser.step()\n",
    "\n",
    "        return semantic_loss.mean().item(), boundary_loss.item(), combined_loss.item(), full_loss.item(), pixel_accuracy, iou, prediction_time\n",
    "\n",
    "    def calc_metrics(self, batch_prediction_tensor, batch_image_label_tensor):\n",
    "        batch_image_label_tensor = batch_image_label_tensor.argmax(dim=1)\n",
    "        batch_prediction_tensor = F.softmax(batch_prediction_tensor, dim=1).detach()\n",
    "\n",
    "        iou_metric = metrics.MulticlassJaccardIndex(num_classes=self.num_classes, average=\"weighted\")\n",
    "        pixel_acc_metric = metrics.MulticlassAccuracy(num_classes=self.num_classes, average=\"weighted\", multidim_average=\"samplewise\")\n",
    "\n",
    "        iou = iou_metric(batch_prediction_tensor, batch_image_label_tensor).item()\n",
    "        pixel_acc = pixel_acc_metric(batch_prediction_tensor, batch_image_label_tensor).mean().item()\n",
    "\n",
    "        return iou, pixel_acc\n",
    "\n",
    "    def get_spec_string(self, override=\"\"):\n",
    "        if override != \"\":\n",
    "            return override\n",
    "\n",
    "        hyperParam_string = self.name + \"-\"\n",
    "        hyperParam_string += str(self.semantic_loss_function).split(\"(\")[0] + \"-\"\n",
    "        hyperParam_string += str(self.optimiser).split(\" \")[0] + \"-\"\n",
    "        hyperParam_string += \"lr\" + str(self.learning_rate)\n",
    "\n",
    "        return hyperParam_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LqSisAeSxi5g"
   },
   "source": [
    "# Training und Testen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Result(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.len = 0\n",
    "\n",
    "        self.semantic_loss = []\n",
    "        self.boundary_loss = []\n",
    "        self.combined_loss = []\n",
    "        self.full_loss = []\n",
    "        self.pixel_acc = []\n",
    "        self.iou = []\n",
    "        self.calc_time = []\n",
    "\n",
    "    def append(self, semantic_loss, boundary_loss, combined_loss, full_loss, pixel_acc, iou, calc_time):\n",
    "        if (semantic_loss is None or\n",
    "                boundary_loss is None or\n",
    "                combined_loss is None or\n",
    "                full_loss is None or\n",
    "                pixel_acc is None or\n",
    "                iou is None or\n",
    "                calc_time is None):\n",
    "            raise ValueError(\"None of the given Parameters can be None!\")\n",
    "\n",
    "        self.semantic_loss.append(semantic_loss)\n",
    "        self.boundary_loss.append(boundary_loss)\n",
    "        self.combined_loss.append(combined_loss)\n",
    "        self.full_loss.append(full_loss)\n",
    "        self.pixel_acc.append(pixel_acc)\n",
    "        self.iou.append(iou)\n",
    "        self.calc_time.append(calc_time)\n",
    "\n",
    "        if (len(self.full_loss) != len(self.semantic_loss) or\n",
    "                len(self.full_loss) != len(self.boundary_loss) or\n",
    "                len(self.full_loss) != len(self.combined_loss) or\n",
    "                len(self.full_loss) != len(self.pixel_acc) or\n",
    "                len(self.full_loss) != len(self.iou) or\n",
    "                len(self.full_loss) != len(self.calc_time)):\n",
    "            raise Exception(\"All properties must be of the same length!\")\n",
    "\n",
    "        self.len += 1\n",
    "\n",
    "    def append_as_result(self, result: 'Result'):\n",
    "        semantic_loss, boundary_loss, combined_loss, full_loss, pixel_acc, iou, calc_time = result.value()\n",
    "        self.append(\n",
    "            semantic_loss=semantic_loss,\n",
    "            boundary_loss=boundary_loss,\n",
    "            combined_loss=combined_loss,\n",
    "            full_loss=full_loss,\n",
    "            pixel_acc=pixel_acc,\n",
    "            iou=iou,\n",
    "            calc_time=calc_time\n",
    "        )\n",
    "\n",
    "    def append_avg(self, result: 'Result'):\n",
    "        mean_semantic_loss, mean_boundary_loss, mean_combined_loss, mean_full_loss, mean_pixel_acc, mean_iou, mean_calc_time = result.average()\n",
    "        self.append(\n",
    "            semantic_loss=mean_semantic_loss,\n",
    "            boundary_loss=mean_boundary_loss,\n",
    "            combined_loss=mean_combined_loss,\n",
    "            full_loss=mean_full_loss,\n",
    "            pixel_acc=mean_pixel_acc,\n",
    "            iou=mean_iou,\n",
    "            calc_time=mean_calc_time\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"\\n\\n=\" * 200, \\\n",
    "            \"\\nSemantic Loss:\", self.semantic_loss, \\\n",
    "            \"\\nBoundary Loss:\", self.boundary_loss, \\\n",
    "            \"\\nCombined Loss:\", self.combined_loss, \\\n",
    "            \"\\nFull Loss:\", self.full_loss, \\\n",
    "            \"\\nPixel Accuracy:\", self.pixel_acc, \\\n",
    "            \"\\nIoU:\", self.iou, \\\n",
    "            \"\\nCalc Time:\", self.calc_time\n",
    "\n",
    "    def get_loss(self):\n",
    "        return self.semantic_loss[-1], self.boundary_loss[-1], self.combined_loss[-1], self.full_loss[-1]\n",
    "\n",
    "    def get_accuracy(self):\n",
    "        return self.iou[-1], self.pixel_acc[-1], self.calc_time[-1]\n",
    "\n",
    "    def value(self):\n",
    "        return (self.semantic_loss,\n",
    "                self.boundary_loss,\n",
    "                self.combined_loss,\n",
    "                self.full_loss,\n",
    "                self.pixel_acc,\n",
    "                self.iou,\n",
    "                self.calc_time)\n",
    "\n",
    "    def value_at_index(self, index: int):\n",
    "        return (self.semantic_loss[index],\n",
    "                self.boundary_loss[index],\n",
    "                self.combined_loss[index],\n",
    "                self.full_loss[index],\n",
    "                self.pixel_acc[index],\n",
    "                self.iou[index],\n",
    "                self.calc_time[index])\n",
    "\n",
    "    def printable_value_at_index(self, index: int):\n",
    "        return \"Semantic Loss: \" + str(self.semantic_loss[index]) + \\\n",
    "            \" | Boundary Loss: \" + str(self.boundary_loss[index]) + \\\n",
    "            \" | Combined Loss: \" + str(self.combined_loss[index]) + \\\n",
    "            \" | Full Loss: \" + str(self.full_loss[index]) + \\\n",
    "            \" | Pixel Accuracy: \" + str(self.pixel_acc[index]) + \\\n",
    "            \" | IoU: \" + str(self.iou[index]) + \\\n",
    "            \" | Prediction Time: \" + str(self.calc_time[index])\n",
    "\n",
    "    def average(self):\n",
    "        return (np.array(self.semantic_loss).mean(),\n",
    "                np.array(self.boundary_loss).mean(),\n",
    "                np.array(self.combined_loss).mean(),\n",
    "                np.array(self.full_loss).mean(),\n",
    "                np.array(self.pixel_acc).mean(),\n",
    "                np.array(self.iou).mean(),\n",
    "                np.array(self.calc_time).mean())\n",
    "\n",
    "    def max(self):\n",
    "        return (np.array(self.semantic_loss).max(),\n",
    "                np.array(self.boundary_loss).max(),\n",
    "                np.array(self.combined_loss).max(),\n",
    "                np.array(self.full_loss).max(),\n",
    "                np.array(self.pixel_acc).max(),\n",
    "                np.array(self.iou).max(),\n",
    "                np.array(self.calc_time).max())\n",
    "\n",
    "    def min(self):\n",
    "        return (np.array(self.semantic_loss).min(),\n",
    "                np.array(self.boundary_loss).min(),\n",
    "                np.array(self.combined_loss).min(),\n",
    "                np.array(self.full_loss).min(),\n",
    "                np.array(self.pixel_acc).min(),\n",
    "                np.array(self.iou).min(),\n",
    "                np.array(self.calc_time).min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### ModelHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1667771325181,
     "user": {
      "displayName": "Fabian Schwickert",
      "userId": "12141023081401838643"
     },
     "user_tz": -60
    },
    "id": "zCELUnVcxlsm"
   },
   "outputs": [],
   "source": [
    "class ModelHandler:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "        self.scheduler = scheduler.LambdaLR(\n",
    "            optimizer=model.optimiser,\n",
    "            lr_lambda= [\n",
    "                lambda epoch: epoch / 10\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.train_results = Result()\n",
    "        self.test_results_with_train_data = Result()\n",
    "        self.test_results_with_test_data = Result()\n",
    "\n",
    "        current_ts = datetime.now()\n",
    "        self.directory = \"Modelle/\" + model.get_spec_string() + \"_\" + current_ts.strftime(\"%d%b%y-%H-%M\")\n",
    "        try:\n",
    "            if not os.path.isdir(self.directory):\n",
    "                os.mkdir(self.directory)\n",
    "                os.mkdir(self.directory + \"/Model\")\n",
    "\n",
    "        except OSError:\n",
    "            raise OSError\n",
    "\n",
    "        else:\n",
    "            model_init_state = deepcopy(model)\n",
    "            torch.save(model_init_state.state_dict(), self.directory + \"/Model/model_init_state.pt\")\n",
    "\n",
    "    def training(self, train_epochs=10, train_batch_size=8, augment=True, print_out=True):\n",
    "        train_loader = DataLoader(dataset=train_set, batch_size=train_batch_size, shuffle=True, num_workers=0, generator=torch.Generator(device=device))\n",
    "        bs1_train_loader = DataLoader(dataset=train_set, batch_size=1, shuffle=True, num_workers=0, generator=torch.Generator(device=device))\n",
    "        test_loader = DataLoader(dataset=test_set, batch_size=1, shuffle=True, num_workers=0, generator=torch.Generator(device=device))\n",
    "\n",
    "        epoch_border = self.model.epochsTrained + train_epochs + 1\n",
    "\n",
    "        while self.model.epochsTrained < epoch_border:\n",
    "            self.model.train()\n",
    "            start_time = datetime.now()\n",
    "\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "\n",
    "            for step, data in enumerate(train_loader, 0):\n",
    "                print_out_ = step % (train_batch_size * 5) == 0 and step != 0\n",
    "\n",
    "                entries = [data]\n",
    "                if augment:\n",
    "                    entries += augment_entry(data[0], data[1], data[2], data[3])\n",
    "\n",
    "                for image, _, class_label, edge in entries:\n",
    "                    semantic_loss, boundary_loss, combined_loss, full_loss, pixel_acc, iou, calc_time = self.model.process_data(PIDNet.train_mode, image, class_label, edge)\n",
    "                    self.train_results.append(\n",
    "                        semantic_loss=semantic_loss,\n",
    "                        boundary_loss=boundary_loss,\n",
    "                        combined_loss=combined_loss,\n",
    "                        full_loss=full_loss,\n",
    "                        pixel_acc=pixel_acc,\n",
    "                        iou=iou,\n",
    "                        calc_time=calc_time\n",
    "                    )\n",
    "\n",
    "                    free_gpu_cache([image, class_label, edge])\n",
    "\n",
    "                if print_out and print_out_:\n",
    "                    print(\"Done\", step, \"Batch-Trainingsteps.\")\n",
    "\n",
    "            train_duration = datetime.now() - start_time\n",
    "\n",
    "            random_index = random.randint(0, len(test_set) - 1)\n",
    "            self.model.eval()\n",
    "            test_image = test_set.__getitem__(random_index)[0]\n",
    "            with torch.no_grad():\n",
    "                classifier.predict(test_image, 1024, 1024, plot=True)\n",
    "\n",
    "            self.testing(bs1_train_loader, self.test_results_with_train_data, print_out=False)\n",
    "            self.testing(test_loader, self.test_results_with_test_data, print_out=False)\n",
    "\n",
    "            self.print_epoch(self.model.epochsTrained, train_duration)\n",
    "            self.save_model(self.model.epochsTrained)\n",
    "\n",
    "            if self.model.epochsTrained == 10 or self.model.epochsTrained == 20:\n",
    "                self.scheduler.step()\n",
    "\n",
    "            self.model.epochsTrained += 1\n",
    "\n",
    "        self.save_results(batch_size=train_batch_size)\n",
    "\n",
    "    def testing(self, dataloader, result: Result, print_out=True):\n",
    "        self.model.eval()\n",
    "        test_results = Result()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for index, data in enumerate(dataloader, 0):\n",
    "                image, _, label, edge = data\n",
    "\n",
    "                semantic_loss, boundary_loss, combined_loss, full_loss, pixel_acc, iou, calc_time = self.model.process_data(PIDNet.test_mode, image, label, edge)\n",
    "                test_results.append(\n",
    "                    semantic_loss=semantic_loss,\n",
    "                    boundary_loss=boundary_loss,\n",
    "                    combined_loss=combined_loss,\n",
    "                    full_loss=full_loss,\n",
    "                    pixel_acc=pixel_acc,\n",
    "                    iou=iou,\n",
    "                    calc_time=calc_time\n",
    "                )\n",
    "\n",
    "                free_gpu_cache([image, label, edge])\n",
    "\n",
    "                if print_out and index % 10 == 0:\n",
    "                    color = 'green' if result.iou > 50 else 'red'\n",
    "                    output = test_results\n",
    "                    output = colored(output, color, attrs=['reverse', 'blink'])\n",
    "                    print(output)\n",
    "\n",
    "        result.append_avg(test_results)\n",
    "\n",
    "    def print_epoch(self, epoch_nr: int, train_duration: str):\n",
    "        print(\"\\n----------------- Epoch\", epoch_nr, \"-----------------\")\n",
    "        print(\"-->  Train-Duration:\", str(train_duration))\n",
    "\n",
    "        print(\"\\n-->  Train-Results:\", self.train_results.printable_value_at_index(-1))\n",
    "        print(\"\\n-->  Test-Results with Train Data:\", self.test_results_with_train_data.printable_value_at_index(-1))\n",
    "        print(\"\\n-->  Test-Results with Test Data:\", self.test_results_with_test_data.printable_value_at_index(-1))\n",
    "        print(\"\\n\", 43 * \"-\")\n",
    "\n",
    "    def save_model(self, epoch_nr: int):\n",
    "        iou, pixel_acc, calc_time = self.test_results_with_test_data.get_accuracy()\n",
    "\n",
    "        filename = \"model_e\" + str(epoch_nr).zfill(2) + \"_pixel-ac\" + str(pixel_acc) + \"_iou\" + str(iou) + \"_time\" + str(calc_time)\n",
    "        torch.save(self.model.state_dict(), self.directory + \"/Model/\" + filename + \".pt\")\n",
    "        print(\"Safed model as \" + filename + \".pt to \" + self.directory + \"/Model/\")\n",
    "\n",
    "    def save_results(self, batch_size):\n",
    "        np.save(self.directory + \"/loss.npy\", self.train_results)\n",
    "        np.save(self.directory + \"/avg_train_loss.npy\", self.test_results_with_train_data)\n",
    "        np.save(self.directory + \"/avg_test_loss.npy\", self.test_results_with_test_data)\n",
    "\n",
    "        model_specs = {\n",
    "            \"model\": {\n",
    "                \"spec_string\": self.model.get_spec_string(),\n",
    "                \"name\": self.model.name,\n",
    "                \"semantic loss-function\": str(self.model.semantic_loss_function).split(\"(\")[0],\n",
    "                \"boundary loss-function\": str(self.model.boundary_loss_function).split(\"(\")[0],\n",
    "                \"optimiser\": str(self.model.optimiser).split(\" \")[0],\n",
    "                \"learning_rate\": self.model.learning_rate\n",
    "            },\n",
    "            \"training\": {\n",
    "                \"batch_size\": batch_size\n",
    "            }\n",
    "        }\n",
    "        json_string = json.dumps(model_specs)\n",
    "        with open(self.directory + \"/spec.json\", \"w\") as file:\n",
    "            file.write(json_string)\n",
    "\n",
    "        #shutil.make_archive(self.directory, 'zip', self.directory)\n",
    "        #shutil.rmtree(self.directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zVq1yRmp6vvF"
   },
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "classifier_model_path = \"\"\n",
    "classifier = PIDNet(\n",
    "    name=\"PIDNet-S\",\n",
    "    learning_rate=1e-2,\n",
    "    out_channels=32,\n",
    "    ppm_channels=96,\n",
    "    head_channels=128,\n",
    "    loss_weights=loss_weights\n",
    ")\n",
    "\n",
    "if classifier_model_path != \"\":\n",
    "    classifier.load_state_dict(torch.load(classifier_model_path))\n",
    "\n",
    "classifier.to(device)\n",
    "\n",
    "print(\"\\n\\n\" + 100 * \"=\")\n",
    "print(100 * \"=\")\n",
    "print(\"Created \" + classifier.get_spec_string())\n",
    "\n",
    "c_handler = ModelHandler(classifier)\n",
    "c_handler.training(train_epochs=50, train_batch_size=16)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNNUHTM7+xq1B3MuW0R6cU0",
   "collapsed_sections": [
    "KROImpmqmoa3",
    "PznDWh1GqyJV",
    "U_u-ATVKm1II",
    "LqSisAeSxi5g"
   ],
   "mount_file_id": "1KZ7Wk1U3uKgqUjGE8fr3Sr0L3xQHRDn7",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "246f92d186daec7b35a678e9bdea74ec397bc9627000380ea7e7a6723aa8fbbb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
